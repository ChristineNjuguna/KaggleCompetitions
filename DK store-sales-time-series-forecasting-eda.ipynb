{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.colors\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\nimport plotly.figure_factory as ff\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-08T12:38:36.973185Z","iopub.execute_input":"2022-09-08T12:38:36.973906Z","iopub.status.idle":"2022-09-08T12:38:40.003345Z","shell.execute_reply.started":"2022-09-08T12:38:36.973816Z","shell.execute_reply":"2022-09-08T12:38:40.002121Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/geopandas/_compat.py:115: UserWarning:\n\nThe Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/store-sales-time-series-forecasting/oil.csv\n/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n/kaggle/input/store-sales-time-series-forecasting/stores.csv\n/kaggle/input/store-sales-time-series-forecasting/train.csv\n/kaggle/input/store-sales-time-series-forecasting/test.csv\n/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"### Load Data Files\n## Train Data\ntrain = pd.read_csv(\"../input/store-sales-time-series-forecasting/train.csv\")\n\n## Test Data\ntest = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\n\n## Stores Data\nstores = pd.read_csv(\"../input/store-sales-time-series-forecasting/stores.csv\")\n\n## Oil Data \noils = pd.read_csv(\"../input/store-sales-time-series-forecasting/oil.csv\")\n\n## Holidays\nholidays = pd.read_csv(\"../input/store-sales-time-series-forecasting/holidays_events.csv\")\n\n## Transactions\ntransactions = pd.read_csv(\"../input/store-sales-time-series-forecasting/transactions.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head\n\ntrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores.head()\n## number of product families in a year\nprint(\"Number of stores : {} \\n\".format(train.store_nbr.nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oils.head()\n\nprint(\"The oils data begins on {} and ends on {}.\\n\".format(oils.date.min(),oils.date.max()))\nprint(\"Number of days with oil prices : {} .\\n\".format(oils.date.nunique()))\n\n\n### Check for duplicates in python\n\nduplicate_dates = oils[\"date\"].duplicated(keep = 'first').nunique()\n\nduplicate_dates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transactions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The transactions data begins on {} and ends on {}.\\n\".format(transactions.date.min(),transactions.date.max()))\nprint(\"Number of days with transactions : {} .\\n\".format(transactions.date.nunique()))\nprint(\"Number of stores with transactions data in every {} \\n\".format(transactions.groupby(pd.to_datetime(train['date'])).store_nbr.nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## number of product families in a year\nprint(\"The training data has the following number of family products in every year {} \\n\".format(train.groupby(pd.to_datetime(train['date']).dt.year).family.nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Number of stores in every year\nprint(\"The training data has the following number of stores in every year {} \\n\".format(train.groupby(pd.to_datetime(train['date']).dt.year).store_nbr.nunique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The training data begins on {} and ends on {}.\\n\".format(train.date.min(),train.date.max()))\nprint(\"Number of days with transactions : {} .\\n\".format(train.date.nunique()))\nprint(\"The test data begins on {} and ends on {}.\\n\".format(test.date.min(),test.date.max()))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize(df,  n_rows_to_show=5):\n    \"\"\"Simply summarize the given DataFrame.\n\n    Parameters:\n    df: pd.DataFrame, raw DataFrame\n    file_name: str, name of the file\n    n_rows_to_show: int, number of rows to show\n    \"\"\"\n    print(f\"Shape: {df.shape}\")\n\n    nan_ratio = pd.isna(df).sum() / len(df) * 100\n    nan_ratio.sort_values(ascending=False, inplace=True)\n    nan_ratio = nan_ratio.to_frame(name='NaN Ratio').T\n    print(\"NaN ratio:\")\n    display(nan_ratio)\n\n    display(df.head(n_rows_to_show))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summarize(train, 5)\nsummarize(test, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merging the datasets","metadata":{}},{"cell_type":"code","source":"## Merge Store Details\ntraining_data = train.merge(stores , how = 'left', on = ['store_nbr'])\n\n## Merge Number of Transactions\ntraining_data = training_data.merge(transactions , how = 'left', on = ['date', 'store_nbr'])\n\n## Merge Number of Transactions\ntraining_data = training_data.merge(oils , how = 'left', on = ['date'])\n\n## Add day of the month \ntraining_data['Month'] = pd.to_datetime(training_data['date']).dt.month\n\n## Add day of the week\ntraining_data['day_of_week'] = pd.to_datetime(training_data['date']).dt.day_name()\n\n## Add Year\ntraining_data['year'] = pd.to_datetime(training_data['date']).dt.year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summarize merged dataset","metadata":{}},{"cell_type":"code","source":"### Check missing values\nsummarize(training_data, 5)\n\n### Check for duplicates\nduplicate_dates = oils[\"date\"].duplicated(keep = 'first').nunique()\nprint(\"Number of days with uplicates stores {}.\\n.format(duplicate_dates)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Find the days when there are most sales and transactions\n### How the price of oil affect the voulme of sales and number of transactions\n### Find the two days where there are no transactions recorded\n## Number of days with no oil prices\n## Determine the family of products under promotion Top 10 and Bottom 10\n## Average Number of sales per month, compared to the average sales in every holiday","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = training_data.loc[training_data[\"year\"] == 2017]\n\n## Average\ndf = df1.groupby('date').mean()['sales']\n\nfig = px.line(df, y=\"sales\" )\nfig.show()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df1.groupby('date').mean()['dcoilwtico']\nfig = px.line(df, y=\"dcoilwtico\" )\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors=px.colors.qualitative.Plotly\ntemp = dict(layout=go.Layout(font=dict(family=\"Franklin Gothic\", size=12), width=1400))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_date=training_data.date.unique()\ntotal_sales=training_data.groupby('date')['sales'].sum().div(100)\npromotion=training_data.groupby('date')['onpromotion'].sum()\navg_sales=training_data.groupby('date')['sales'].mean()\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=train_date,\n        y= total_sales,\n        name = \"total sales\", mode='lines'\n    ))\n\nfig.add_trace(\n    go.Scatter(\n        x=train_date,\n        y= promotion,\n        name = \"promotionL\", mode='lines'\n    ))\n\n# fig.add_trace(\n#     go.Bar(\n#         x=train_date,\n#         y=promotion,\n#         name = \"promotion\"\n#     ))\n\n\nfig.update_xaxes(rangeslider_visible= True,\n                 rangeselector=dict(\n                     buttons=list([\n                         dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n                         dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n                         dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n                         dict(count=4, label=\"4y\", step=\"year\", stepmode=\"backward\"),\n                         dict(step=\"all\")])))\nfig.update_layout(template=temp,title='Total Sales/100  and Items on Promotion', \n                  autosize=False, \n                  width=1400, \n                  height=700, \n                  xaxis_title=\"Date\", \n                  yaxis_title=\"\",\n                  hovermode='x unified',\n                  showlegend=True)\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Sales with the price of oil","metadata":{}},{"cell_type":"code","source":"### drop days without oil prices\n\ntraining_data1 = training_data.copy()\nprint(training_data1.shape)\n\ntraining_data1 = training_data1.dropna(subset=['dcoilwtico'])\nprint(training_data1.shape)\n\ntransactions_num=training_data1.groupby(['date', 'store_nbr'])['transactions'].first()\n\ntransactions_num.columns = [\n    'date', \n    'store_nbr',\n    'transactions']\ntransactions_num = transactions_num.reset_index()\n\ntransactions_num = transactions_num.groupby('date')['transactions'].sum().div(1000)\n\n\ntrain_date=training_data1.date.unique()\n\n\ntrain_date1 =pd.DataFrame(train_date, columns = ['date'])\n\ntrain_date1= train_date1.merge(day, on = ['date'])\n\ntrain_date1['date_day'] = train_date1['date'] + \" \" + train_date1['day_of_week']\n\n\noil_prices=training_data1.groupby('date')['dcoilwtico'].first()\n\nsales=training_data1.groupby('date')['sales'].sum().div(20000)\n\nday = training_data1.groupby('date')['day_of_week'].first()\n\n\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x= train_date1['date_day'], ##[train_date, day],\n        y= oil_prices,\n        name = 'Oil Prices',\n        mode='lines'\n    ))\n\nfig.add_trace(\n    go.Scatter(\n        x= train_date1['date_day'], ## [train_date, day],\n        y= sales,\n        name = \"Sales/(10000)\",\n        mode='lines'\n    ))\n\nfig.add_trace(\n    go.Scatter(\n        x= train_date1['date_day'], ##[train_date, day],\n        y= transactions_num,\n        name = \"Number of Transactions\", mode='lines'\n    ))\n\nfig.update_xaxes(rangeslider_visible= True,\n                 rangeselector=dict(\n                     buttons=list([\n                         dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n                         dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n                         dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n                         dict(count=4, label=\"4y\", step=\"year\", stepmode=\"backward\"),\n                         dict(step=\"all\")])))\nfig.update_layout(\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    late=temp,title='Sales/10000  and Oil prices and Number of Transactions', \n                  autosize=False, \n                  width=1400, \n                  height=700, \n                  xaxis_title=\"Date\", \n                  yaxis_title=\"\",\n                  hovermode='x unified',\n                  showlegend=True)\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Oil Prices and days of the week","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"oil_days = training_data.groupby(\"day_of_week\")['dcoilwtico'].count()\nprint(oil_days)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check = train['date'].value_counts().reset_index()\ncheck=training_data.groupby(['family','year']).agg({\"sales\" : \"mean\"}).reset_index()\n\ncheck.columns = [\n    'family', \n    'year',\n    'sales'\n]\n\ncheck = check.sort_values('sales', ascending=False)\n\nfig = px.histogram(check, x=\"family\", y=\"sales\",\n             color='year', barmode='group',\n             height=400)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check = train['date'].value_counts().reset_index()\ncheck=training_data.groupby(['family','year']).agg({\"sales\" : \"sum\"}).reset_index()\n\ncheck.columns = [\n    'family', \n    'year',\n    'sales'\n]\n\ncheck = check.sort_values('sales', ascending=False)\n\nfig = px.histogram(check, x=\"family\", y=\"sales\",\n             color='year', barmode='group',\n             height=400)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntraining_data =training_data.sort_values('sales', ascending=False)\n\nfig = px.box(training_data, x=\"family\", y=\"sales\",  color='year',\n             height=400)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}